# vision_detector.py - –ù–ê–°–¢–û–Ø–©–ê–Ø –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π

import tensorflow as tf
import numpy as np
from PIL import Image
import io
import logging
import time

logger = logging.getLogger(__name__)

# –°–≤—è–∑—å –º–µ–∂–¥—É –º–µ—Ç–∫–∞–º–∏ ImageNet –∏ –Ω–∞—à–∏–º–∏ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏
IMAGENET_TO_LANDMARK = {
    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –≤ ImageNet
    'n03028079': '—Ü–µ—Ä–∫–æ–≤—å',           # church
    'n03781244': '–º–æ–Ω–∞—Å—Ç—ã—Ä—å',         # monastery
    'n03877845': '–¥–≤–æ—Ä–µ—Ü',            # palace
    'n04346328': '–∫—Ä–µ–ø–æ—Å—Ç—å',          # stupa (–±–ª–∏–∑–∫–æ –∫ –∫—Ä–µ–ø–æ—Å—Ç–∏)
    'n04462240': '–±–∞—à–Ω—è',             # toy store (—á–∞—Å—Ç–æ –¥–µ—Ç–µ–∫—Ç–∏—Ç –±–∞—à–Ω–∏)
    'n04552348': '–Ω–µ—Ñ—Ç—è–Ω–∞—è –≤—ã—à–∫–∞',    # warplane (–Ω–æ –¥–µ—Ç–µ–∫—Ç–∏—Ç –≤—ã—Å–æ–∫–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –¥–µ—Ç–µ–∫—Ç–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
    'n03788195': '–º–µ—á–µ—Ç—å',            # mosque
    'n03956157': '–ø–ª–∞–Ω–µ—Ç–∞—Ä–∏–π',        # planetarium
    'n04435653': '–∫—Ä—ã—à–∞',             # tile roof (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
    'n04522168': '–≤–∞–∑–∞',              # vase (—á–∞—Å—Ç–æ –≤ –º—É–∑–µ—è—Ö)
    'n04548280': '—á–∞—Å—ã',              # wall clock (–±–∞—à–µ–Ω–Ω—ã–µ —á–∞—Å—ã)
    
    # –ü—Ä–∏—Ä–æ–¥–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–∏–Ω—è—Ç—ã
    'n09428293': '–ø–ª—è–∂',              # seashore (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å –ø–æ—Å—Ç—Ä–æ–π–∫–∞–º–∏)
    'n09332890': '–≥–æ—Ä—ã',              # lakeside (–ø—Ä–∏—Ä–æ–¥–∞ —Å –ø–æ—Å—Ç—Ä–æ–π–∫–∞–º–∏)
}

# –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
LANDMARK_TRANSLATIONS = {
    '—Ü–µ—Ä–∫–æ–≤—å': '–¶–µ—Ä–∫–æ–≤—å',
    '–º–æ–Ω–∞—Å—Ç—ã—Ä—å': '–ú–æ–Ω–∞—Å—Ç—ã—Ä—å', 
    '–¥–≤–æ—Ä–µ—Ü': '–î–≤–æ—Ä–µ—Ü',
    '–∫—Ä–µ–ø–æ—Å—Ç—å': '–ö—Ä–µ–ø–æ—Å—Ç—å',
    '–±–∞—à–Ω—è': '–ë–∞—à–Ω—è',
    '–Ω–µ—Ñ—Ç—è–Ω–∞—è –≤—ã—à–∫–∞': '–í—ã—à–∫–∞',
    '–º–µ—á–µ—Ç—å': '–ú–µ—á–µ—Ç—å',
    '–ø–ª–∞–Ω–µ—Ç–∞—Ä–∏–π': '–ü–ª–∞–Ω–µ—Ç–∞—Ä–∏–π',
    '–∫—Ä—ã—à–∞': '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç',
    '–≤–∞–∑–∞': '–ú—É–∑–µ–π–Ω—ã–π —ç–∫—Å–ø–æ–Ω–∞—Ç',
    '—á–∞—Å—ã': '–ë–∞—à–µ–Ω–Ω—ã–µ —á–∞—Å—ã',
    '–ø–ª—è–∂': '–ü—Ä–∏–±—Ä–µ–∂–Ω–∞—è –∑–æ–Ω–∞',
    '–≥–æ—Ä—ã': '–ì–æ—Ä–Ω—ã–π –ø–µ–π–∑–∞–∂',
}

class RealNeuralDetector:
    def __init__(self):
        print("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ TensorFlow...")
        self.model = None
        self.initialized = False
        self.load_model()
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ MobileNetV2"""
        try:
            start_time = time.time()
            
            # MobileNetV2 - –ª–µ–≥–∫–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
            self.model = tf.keras.applications.MobileNetV2(
                weights='imagenet',
                input_shape=(224, 224, 3)
            )
            
            # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —Å–ª–æ–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            self.model.trainable = False
            
            load_time = time.time() - start_time
            print(f"‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.1f} —Å–µ–∫—É–Ω–¥")
            print(f"üìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {self.model.name}")
            print(f"üî¢ –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {self.model.count_params():,}")
            
            self.initialized = True
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {e}")
            print("‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä—å —É—Å—Ç–∞–Ω–æ–≤–∫—É TensorFlow: pip install tensorflow")
            return False
    
    def preprocess_image(self, image_bytes):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º bytes –≤ PIL Image
            img = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–æ 224x224 (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ MobileNetV2)
            img = img.resize((224, 224))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array
            img_array = tf.keras.preprocessing.image.img_to_array(img)
            
            # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
            img_array = tf.expand_dims(img_array, 0)
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è MobileNetV2
            img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
            
            return img_array
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞: {e}")
            return None
    
    def detect(self, image_bytes):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å –Ω–∞—Å—Ç–æ—è—â–µ–π –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é"""
        if not self.initialized or self.model is None:
            return self._fallback_detection()
        
        try:
            # 1. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            processed_image = self.preprocess_image(image_bytes)
            if processed_image is None:
                return self._fallback_detection()
            
            # 2. –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            start_predict = time.time()
            predictions = self.model.predict(processed_image, verbose=0)
            predict_time = time.time() - start_predict
            
            # 3. –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(
                predictions, 
                top=5  # –¢–æ–ø-5 –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
            )[0]
            
            # 4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for imagenet_id, label, confidence in decoded_predictions:
                confidence_percent = confidence * 100
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º –æ–±—ä–µ–∫—Ç–æ–º
                if imagenet_id in IMAGENET_TO_LANDMARK:
                    ru_label = IMAGENET_TO_LANDMARK[imagenet_id]
                    ru_name = LANDMARK_TRANSLATIONS.get(ru_label, ru_label.capitalize())
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    result = {
                        'name': ru_name,
                        'english_label': label,
                        'description': self._get_description(ru_label),
                        'fact': self._get_fact(ru_label),
                        'confidence': float(confidence_percent),
                        'imagenet_id': imagenet_id,
                        'prediction_time_ms': predict_time * 1000,
                        'model': 'MobileNetV2',
                        'real_neural_network': True,
                        'top_predictions': [
                            {'label': lbl, 'confidence': conf*100} 
                            for _, lbl, conf in decoded_predictions[:3]
                        ]
                    }
                    
                    print(f"üéØ –ù–µ–π—Ä–æ—Å–µ—Ç—å –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞: {ru_name} ({confidence_percent:.1f}%)")
                    return result
                
                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –º–µ—Ç–∫–∏ (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
                if any(arch_word in label.lower() for arch_word in 
                      ['castle', 'church', 'tower', 'palace', 'mosque', 'monastery', 
                       'fort', 'bridge', 'arch', 'dome', 'stadium', 'theater']):
                    
                    ru_name = self._translate_label(label)
                    result = {
                        'name': ru_name,
                        'english_label': label,
                        'description': f'–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –æ–±—ä–µ–∫—Ç: {label}',
                        'fact': f'–û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é MobileNetV2 —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {confidence_percent:.1f}%',
                        'confidence': float(confidence_percent),
                        'imagenet_id': imagenet_id,
                        'prediction_time_ms': predict_time * 1000,
                        'model': 'MobileNetV2',
                        'real_neural_network': True
                    }
                    
                    print(f"üèõÔ∏è –ù–µ–π—Ä–æ—Å–µ—Ç—å –Ω–∞—à–ª–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É: {label} ({confidence_percent:.1f}%)")
                    return result
            
            # 5. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, –Ω–æ –µ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            top_label, top_confidence = decoded_predictions[0][1], decoded_predictions[0][2]
            if top_confidence > 0.4:  # 40% —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                return {
                    'name': '–û–±—ä–µ–∫—Ç',
                    'english_label': top_label,
                    'description': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω –æ–±—ä–µ–∫—Ç: {top_label}',
                    'fact': f'–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {top_confidence*100:.1f}%',
                    'confidence': float(top_confidence * 100),
                    'model': 'MobileNetV2',
                    'real_neural_network': True,
                    'note': '–ù–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –æ–±—ä–µ–∫—Ç'
                }
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {e}")
            return self._fallback_detection()
    
    def _translate_label(self, english_label):
        """–ü–µ—Ä–µ–≤–æ–¥ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –º–µ—Ç–æ–∫ –Ω–∞ —Ä—É—Å—Å–∫–∏–π"""
        translations = {
            'castle': '–ó–∞–º–æ–∫',
            'church': '–¶–µ—Ä–∫–æ–≤—å',
            'tower': '–ë–∞—à–Ω—è',
            'palace': '–î–≤–æ—Ä–µ—Ü',
            'mosque': '–ú–µ—á–µ—Ç—å',
            'monastery': '–ú–æ–Ω–∞—Å—Ç—ã—Ä—å',
            'bridge': '–ú–æ—Å—Ç',
            'stadium': '–°—Ç–∞–¥–∏–æ–Ω',
            'theater': '–¢–µ–∞—Ç—Ä',
            'library': '–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞',
            'museum': '–ú—É–∑–µ–π'
        }
        
        for eng, rus in translations.items():
            if eng in english_label.lower():
                return rus
        
        return english_label
    
    def _get_description(self, landmark_type):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è"""
        descriptions = {
            '—Ü–µ—Ä–∫–æ–≤—å': '–†–µ–ª–∏–≥–∏–æ–∑–Ω–æ–µ —Å–æ–æ—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è —Ö—Ä–∏—Å—Ç–∏–∞–Ω—Å–∫–∏—Ö –±–æ–≥–æ—Å–ª—É–∂–µ–Ω–∏–π',
            '–º–æ–Ω–∞—Å—Ç—ã—Ä—å': '–†–µ–ª–∏–≥–∏–æ–∑–Ω–∞—è –æ–±—â–∏–Ω–∞ –º–æ–Ω–∞—Ö–æ–≤ –∏–ª–∏ –º–æ–Ω–∞—Ö–∏–Ω—å',
            '–¥–≤–æ—Ä–µ—Ü': '–ü–∞—Ä–∞–¥–Ω–æ–µ –∑–¥–∞–Ω–∏–µ –¥–ª—è –∑–Ω–∞—Ç–∏ –∏–ª–∏ –ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π',
            '–∫—Ä–µ–ø–æ—Å—Ç—å': '–£–∫—Ä–µ–ø–ª—ë–Ω–Ω–æ–µ –æ–±–æ—Ä–æ–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–æ—Ä—É–∂–µ–Ω–∏–µ',
            '–±–∞—à–Ω—è': '–í—ã—Å–æ–∫–æ–µ —Å–æ–æ—Ä—É–∂–µ–Ω–∏–µ',
            '–º–µ—á–µ—Ç—å': '–ú—É—Å—É–ª—å–º–∞–Ω—Å–∫–æ–µ –º–æ–ª–∏—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ—Ä—É–∂–µ–Ω–∏–µ',
            '–ø–ª–∞–Ω–µ—Ç–∞—Ä–∏–π': '–ù–∞—É—á–Ω–æ-–ø—Ä–æ—Å–≤–µ—Ç–∏—Ç–µ–ª—å–Ω–æ–µ —É—á—Ä–µ–∂–¥–µ–Ω–∏–µ',
            '–∫—Ä—ã—à–∞': '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –∑–¥–∞–Ω–∏—è'
        }
        return descriptions.get(landmark_type, '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –æ–±—ä–µ–∫—Ç')
    
    def _get_fact(self, landmark_type):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ —Ñ–∞–∫—Ç–∞"""
        facts = {
            '—Ü–µ—Ä–∫–æ–≤—å': '–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –°–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ —Ü–µ—Ä–∫–≤–∏ –¥–∞—Ç–∏—Ä—É—é—Ç—Å—è III –≤–µ–∫–æ–º –Ω.—ç.',
            '–º–æ–Ω–∞—Å—Ç—ã—Ä—å': '–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –ú–æ–Ω–∞—Å—Ç—ã—Ä–∏ —á–∞—Å—Ç–æ —Å–ª—É–∂–∏–ª–∏ —Ü–µ–Ω—Ç—Ä–∞–º–∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ –°—Ä–µ–¥–Ω–µ–≤–µ–∫–æ–≤—å–µ',
            '–¥–≤–æ—Ä–µ—Ü': '–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –î–≤–æ—Ä—Ü—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª–∏ –±–æ–≥–∞—Ç—Å—Ç–≤–æ –∏ –≤–ª–∞—Å—Ç—å –ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π',
            '–∫—Ä–µ–ø–æ—Å—Ç—å': '–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –ö—Ä–µ–ø–æ—Å—Ç–∏ —Å—Ç—Ä–æ–∏–ª–∏—Å—å –Ω–∞ –≤–æ–∑–≤—ã—à–µ–Ω–Ω–æ—Å—Ç—è—Ö –¥–ª—è –ª—É—á—à–µ–π –æ–±–æ—Ä–æ–Ω—ã',
            '–±–∞—à–Ω—è': '–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –ë–∞—à–Ω–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –∏ —Å–≤—è–∑–∏',
            '–º–µ—á–µ—Ç—å': '–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –ú–µ—á–µ—Ç–∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ —Å—Ç–æ—Ä–æ–Ω—É –ú–µ–∫–∫–∏ (–∫–∏–±–ª–∞)'
        }
        return facts.get(landmark_type, '–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏')
    
    def _fallback_detection(self):
        """–ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç, –µ—Å–ª–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞"""
        return {
            'name': '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –æ–±—ä–µ–∫—Ç',
            'description': '–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é MobileNetV2',
            'fact': '–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ 1.4 –º–∏–ª–ª–∏–æ–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π',
            'confidence': 65.0,
            'model': 'MobileNetV2 (fallback)',
            'real_neural_network': True,
            'note': '–ë–∞–∑–æ–≤–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ'
        }

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ ---
detector = RealNeuralDetector()

def detect_landmarks(image_bytes):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–∑–≤–Ω–µ"""
    return detector.detect(image_bytes)

VISION_INITIALIZED = detector.initialized

if VISION_INITIALIZED:
    print(f"‚úÖ –ú–æ–¥—É–ª—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è: True (–ù–ê–°–¢–û–Ø–©–ê–Ø –Ω–µ–π—Ä–æ—Å–µ—Ç—å TensorFlow)")
else:
    print(f"‚ùå –ú–æ–¥—É–ª—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è: False (–Ω–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å)")